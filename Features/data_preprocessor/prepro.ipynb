{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72dc409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_raw = pd.read_csv('/Users/javier/VSCODE/datahub/enron_data_fraud_labeled.csv') \n",
    "\n",
    "# filtered_raw = full_raw['Body'].iloc[:100_000]\n",
    "\n",
    "# filtered_raw.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_raw = pd.read_csv('/Users/javier/VSCODE/local/DSA4213_vsc/final_project/test.csv')\n",
    "filtered_raw= filtered_raw.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "910a69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Hi John,  Please check out our new product at https://www.example.com/special-offer.  You can also visit www.testsite.org for more details.  I've attached the latest report as quarterly_results.pdf and also a backup copy as report.docx send to abc@gmail.com and john.doe@gmail.org. Let me know if you have trouble opening summary.xlsx.  Best,  Alice\"\n",
    "\n",
    "html_text = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Quarterly Update</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Special Offer!</h1>\n",
    "    <p>Dear customer,</p>\n",
    "    \n",
    "    <p>\n",
    "      Please download the latest reports:\n",
    "      <a href=\"https://example.com/files/quarterly_report.pdf\">Quarterly Report</a>,\n",
    "      <a href=\"https://example.com/files/summary.docx\">Summary</a>,\n",
    "      and <a href=\"https://example.com/files/data.xlsx\">Data File</a>.\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      If you cannot access the files, please email \n",
    "      <a href=\"mailto:support@example.com\">support@example.com</a>.\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      Alternatively, you may contact John at john.doe@workmail.org or visit our site \n",
    "      <a href=\"http://www.testsite.org\">www.testsite.org</a>.\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      Attached reference documents: <b>budget_2024.pdf</b>, <b>plan_final.docx</b>\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      loveeeeeeeeee\n",
    "      lovee33333eeee\n",
    "      a-p-p-l-e\n",
    "      b.a.n.a.n.a\n",
    "      fr33 c4$h \n",
    "      Helloüåç!! This*** is a test üòé #spam @user $100...\n",
    "      45 46 20000 32323 $222.22\n",
    "    </p\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2efab4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking special token\n",
    "def mask_tokens(text):\n",
    "    # replace URLs (http, https, www)\n",
    "    text = re.sub(r'(https?://\\S+|www\\.\\S+)', '<URL>', text)\n",
    "\n",
    "    # replace common file extensions (customize list)\n",
    "    text = re.sub(r'\\b[\\w\\-]+\\.(pdf|docx|xlsx|txt|csv|tar|doc\\.gz|doc)\\b', '<FILE>', text)\n",
    "\n",
    "    # emails\n",
    "    text = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '<EMAIL>', text)\n",
    "\n",
    "    # money \n",
    "    text = re.sub(r'\\$\\d+(?:\\.\\d{2})?','<MONEY>',text)\n",
    "\n",
    "    # numbers \n",
    "    text = re.sub(r'\\b\\d+\\b','<NUMBER>',text)\n",
    "    text = text.replace('<NUMBER>', '')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# un HTML raw text \n",
    "def strip_html(raw_html):\n",
    "    \"\"\"\n",
    "    Strip HTML tags, scripts, styles, and normalize whitespace\n",
    "    to return clean raw text from HTML emails.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "\n",
    "    \n",
    "    for a in soup.find_all(\"a\"):\n",
    "        a_attribute = a['href'] \n",
    "\n",
    "        a_attribute = mask_tokens(a_attribute)\n",
    "\n",
    "        if a_attribute == '<URL>' : \n",
    "            a.replace_with('<URL>')\n",
    "\n",
    "        elif a_attribute =='<EMAIL>' : \n",
    "            a.replace_with('<EMAIL>')\n",
    "        \n",
    "        elif a_attribute == '<FILE>' : \n",
    "            a.replace_with('<FILE>')\n",
    "\n",
    "        elif a_attribute == '<MONEY>' : \n",
    "            a.replace_with('<MONEY>')\n",
    "        \n",
    "        elif a_attribute == '<NUMBER>' : \n",
    "            a.replace_with('<NUMBER>')\n",
    "\n",
    "    # remove script, style, head, and metadata tags\n",
    "    for tag in soup([\"script\", \"style\", \"head\", \"title\", \"meta\", \"[document]\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # extract text\n",
    "    text = soup.get_text(separator=\" \")\n",
    "\n",
    "    # normalize unicode \n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # replace non-breaking spaces specifically (unicode)\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "\n",
    "    # collapse all whitespace tokens (line breaks, tabs, multiple spaces) into one space and remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # rim leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# special case handling\n",
    "mapper = str.maketrans({\n",
    "    '0':'o','1':'l','3':'e','4':'a','5':'s','7':'t','$':'s','@':'a'\n",
    "})\n",
    "\n",
    "def deobfuscate_words(text):\n",
    "    # replace text to number \n",
    "    text = text.translate(mapper)\n",
    "    # remove weird spaces etc \n",
    "    text = re.sub(r'(?i)(?<=\\w)[^A-Za-z0-9\\s]{1,3}(?=\\w)', '', text)\n",
    "    return text\n",
    "\n",
    "def word_capper(text):\n",
    "    text = re.sub(r'(.)\\1{' + str(2) + r',}', lambda m: m.group(1)*2, text)\n",
    "    text = re.sub(r'([!?.,])\\1{1,}', r'\\1\\1', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# whitelist filtering\n",
    "def char_lvl_whitelist_filter(text): \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\,\\!\\?\\'\\\":;\\-\\_\\(\\)\\@\\#\\$\\%\\^\\&\\<\\>]', '', text)\n",
    "    return text\n",
    "\n",
    "# word level processor \n",
    "def lemmatizer(text) :\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    split = []\n",
    "    sentence = ''\n",
    "\n",
    "    text_split = text.split(' ')\n",
    "\n",
    "    for word in text_split : \n",
    "        lemmatizer.lemmatize(word)\n",
    "        split.append(word)\n",
    "        \n",
    "        sentence.join(word)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c550281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Offer! Dear customer, Please download the latest reports: <URL> , <URL> , and <URL> . If you cannot access the files, please email <EMAIL> . Alternatively, you may contact John at <EMAIL> or visit our site <URL> . Attached reference documents: <FILE> , <FILE> lovee lovee apple banana free cash Hello!! This is a test  #spam auser <MONEY>.. <NUMBER> <NUMBER> <NUMBER> <NUMBER> <MONEY>\n"
     ]
    }
   ],
   "source": [
    "raw = html_text\n",
    "raw = strip_html(raw) # process html first to capture links from <a> tags\n",
    "raw = mask_tokens(raw) # mask special tokens \n",
    "raw = deobfuscate_words(raw)\n",
    "raw = word_capper(raw)\n",
    "raw = char_lvl_whitelist_filter(raw)\n",
    "\n",
    "print(raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225047f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_email_text(\n",
    "    input_df\n",
    "): \n",
    "    \"\"\"\n",
    "    input : dataframe with only text column \n",
    "    output : dataframe with cleaned sentences\n",
    "    \"\"\"\n",
    "    # loop every row \n",
    "    for raw in input_df :\n",
    "        \n",
    "        \n",
    "        raw = strip_html(raw) # process html first to capture links from <a> tags\n",
    "        raw = mask_tokens(raw) # mask special tokens \n",
    "        raw = deobfuscate_words(raw)\n",
    "        raw = word_capper(raw)\n",
    "        raw = lemmatizer(raw)\n",
    "        raw = char_lvl_whitelist_filter(raw)\n",
    "        # print(raw)\n",
    "\n",
    "    return input_df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92fe7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Status John: I'm not really sure what happened...\n",
      "Name: Body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "debug_test = filtered_raw['Body'].iloc[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5eb2cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status John: I'm not really sure what happened between us.? I was under the impression after my visit to Houston that we were about to enter into a trial agreement for my advisory work.? Somehow,?this never occurred.? Did I say or do something wrong to screw this up??? I don't know if you've blown this whole thing off, but I still hope you are interested in trying?to create an arrangement.? As a courtesy, here is my report from this past weekend.? If you are no longer interested in my work, please tell me so.??Best wishes, Mark Sagel Psytech Analytics (410)308-0245? energy2000-1112.doc\n",
      "Status John: I'm not really sure what happened between us.? I was under the impression after my visit to Houston that we were about to enter into a trial agreement for my advisory work.? Somehow,?this never occurred.? Did I say or do something wrong to screw this up??? I don't know if you've blown this whole thing off, but I still hope you are interested in trying?to create an arrangement.? As a courtesy, here is my report from this past weekend.? If you are no longer interested in my work, please tell me so.??Best wishes, Mark Sagel Psytech Analytics (410)308-0245? energy2000-1112.doc\n"
     ]
    }
   ],
   "source": [
    "for x in debug_test: \n",
    "    print(x)\n",
    "\n",
    "res = preprocess_email_text(debug_test)\n",
    "\n",
    "\n",
    "for x in res: \n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee358285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa4213_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
