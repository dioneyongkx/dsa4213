{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sentencepiece as spm\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_raw = pd.read_csv('/Users/javier/VSCODE/datahub/enron_data_fraud_labeled.csv') \n",
    "\n",
    "# filtered_raw = full_raw[['Body','Label']].iloc[:100_000]\n",
    "\n",
    "# filtered_raw.to_csv('test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_raw = pd.read_csv('/Users/javier/VSCODE/local/DSA4213_vsc/final_project/test.csv')\n",
    "print(filtered_raw.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Hi John,  Please check out our new product at https://www.example.com/special-offer.  You can also visit www.testsite.org for more details.  I've attached the latest report as quarterly_results.pdf and also a backup copy as report.docx send to abc@gmail.com and john.doe@gmail.org. Let me know if you have trouble opening summary.xlsx.  Best,  Alice\"\n",
    "\n",
    "html_text = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Quarterly Update</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Special Offer!</h1>\n",
    "    <p>Dear customer,</p>\n",
    "    \n",
    "    <p>\n",
    "      Please download the latest reports:\n",
    "      <a href=\"https://example.com/files/quarterly_report.pdf\">Quarterly Report</a>,\n",
    "      <a href=\"https://example.com/files/summary.docx\">Summary</a>,\n",
    "      and <a href=\"https://example.com/files/data.xlsx\">Data File</a>.\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      If you cannot access the files, please email \n",
    "      <a href=\"mailto:support@example.com\">support@example.com</a>.\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      Alternatively, you may contact John at john.doe@workmail.org or visit our site \n",
    "      <a href=\"http://www.testsite.org\">www.testsite.org</a>.\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      Attached reference documents: <b>budget_2024.pdf</b>, <b>plan_final.docx</b>\n",
    "    </p>\n",
    "\n",
    "    <p>\n",
    "      loveeeeeeeeee\n",
    "      lovee33333eeee\n",
    "      a-p-p-l-e\n",
    "      b.a.n.a.n.a\n",
    "      fr33 c4$h \n",
    "      Helloüåç!! This*** is a test üòé #spam @user $100...\n",
    "      45 46 20000 32323 $222.22\n",
    "    </p\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e469e70",
   "metadata": {},
   "source": [
    "#### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efab4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking special token\n",
    "def mask_tokens(text):\n",
    "    # replace URLs (http, https, www)\n",
    "    text = re.sub(r'(https?://\\S+|www\\.\\S+)', '<URL>', text)\n",
    "\n",
    "    # replace common file extensions (customize list)\n",
    "    text = re.sub(r'\\b[\\w\\-]+\\.(pdf|docx|xlsx|txt|csv|tar|doc\\.gz|doc)\\b', '<FILE>', text)\n",
    "\n",
    "    # emails\n",
    "    text = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '<EMAIL>', text)\n",
    "\n",
    "    # money \n",
    "    text = re.sub(r'\\$\\d+(?:\\.\\d{2})?','<MONEY>',text)\n",
    "\n",
    "    # numbers \n",
    "    text = re.sub(r'\\b\\d+\\b','<NUMBER>',text)\n",
    "    text = text.replace('<NUMBER>', '')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# un HTML raw text \n",
    "def strip_html(raw_html):\n",
    "    \"\"\"\n",
    "    Strip HTML tags, scripts, styles, and normalize whitespace\n",
    "    to return clean raw text from HTML emails.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "\n",
    "    \n",
    "    for a in soup.find_all(\"a\"):\n",
    "        a_attribute = a['href'] \n",
    "\n",
    "        a_attribute = mask_tokens(a_attribute)\n",
    "\n",
    "        if a_attribute == '<URL>' : \n",
    "            a.replace_with('<URL>')\n",
    "\n",
    "        elif a_attribute =='<EMAIL>' : \n",
    "            a.replace_with('<EMAIL>')\n",
    "        \n",
    "        elif a_attribute == '<FILE>' : \n",
    "            a.replace_with('<FILE>')\n",
    "\n",
    "        elif a_attribute == '<MONEY>' : \n",
    "            a.replace_with('<MONEY>')\n",
    "        \n",
    "        elif a_attribute == '<NUMBER>' : \n",
    "            a.replace_with('<NUMBER>')\n",
    "\n",
    "    # remove script, style, head, and metadata tags\n",
    "    for tag in soup([\"script\", \"style\", \"head\", \"title\", \"meta\", \"[document]\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # extract text\n",
    "    text = soup.get_text(separator=\" \")\n",
    "\n",
    "    # normalize unicode \n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # replace non-breaking spaces specifically (unicode)\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "\n",
    "    # collapse all whitespace tokens (line breaks, tabs, multiple spaces) into one space and remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # rim leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# special case handling\n",
    "mapper = str.maketrans({\n",
    "    '0':'o','1':'l','3':'e','4':'a','5':'s','7':'t','$':'s','@':'a'\n",
    "})\n",
    "\n",
    "def deobfuscate_words(text):\n",
    "    \"\"\"\n",
    "    capture non-alphanumeric sequence in windows of 1-3 and replaces with ' ' \n",
    "    l-o-v-e -> l-o , - is detected and removed -> love\n",
    "    \"\"\"\n",
    "    # replace text to number \n",
    "    text = text.translate(mapper)\n",
    "    # remove weird spaces etc \n",
    "    text = re.sub(r'(?i)(?<=\\w)[^A-Za-z0-9\\s]{1,3}(?=\\w)', '', text)\n",
    "    return text\n",
    "\n",
    "def word_capper(text):\n",
    "    text = re.sub(r'(.)\\1{' + str(2) + r',}', lambda m: m.group(1)*2, text)\n",
    "    text = re.sub(r'([!?.,])\\1{1,}', r'\\1\\1', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# whitelist filtering\n",
    "def char_lvl_whitelist_filter(text): \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\,\\!\\?\\'\\\":;\\-\\_\\(\\)\\@\\#\\$\\%\\^\\&\\<\\>]', '', text)\n",
    "    return text\n",
    "\n",
    "# word level processor \n",
    "def lemmatizer(text) :\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = ''\n",
    "\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "    return sentence.join(lemmatized_words)\n",
    "\n",
    "#final clean\n",
    "def final_punc_removal(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s<>]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2db1f0",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_email_text(raw): \n",
    "    \"\"\"\n",
    "    the whole pipeline of processing\n",
    "    input : dataframe with text column and ham/spam label\n",
    "    output : dataframe with cleaned sentences and ham/spam label\n",
    "    \"\"\"\n",
    "    raw = strip_html(raw) # process html first to capture links from <a> tags\n",
    "    raw = mask_tokens(raw) # mask special tokens \n",
    "    raw = deobfuscate_words(raw)\n",
    "    raw = word_capper(raw)\n",
    "    raw = lemmatizer(raw)\n",
    "    raw = char_lvl_whitelist_filter(raw)\n",
    "    raw = final_punc_removal(raw)\n",
    "    raw = raw.lower()\n",
    "    return raw\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c92fe7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Body     object\n",
      "Label     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "debug_test = filtered_raw[['Body','Label']].iloc[:1]\n",
    "debug_test['Body'] = debug_test['Body'].apply(preprocess_email_text)\n",
    "print(type(debug_test))\n",
    "print(debug_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee358285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_builder(\n",
    "    input_df\n",
    ") : \n",
    "    \n",
    "    input_df[\"Body\"].to_csv(\"emails_clean.txt\", index=False, header=False)\n",
    "\n",
    "    # train SentencePiece model\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        \"--input=emails_clean.txt \"\n",
    "        \"--model_prefix=email_sp \"\n",
    "        \"--vocab_size=40 \"\n",
    "        \"--character_coverage=1.0 \"\n",
    "        \"--user_defined_symbols=<url>,<email>,<file>,<money>\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28bc40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_to_id_mapper(\n",
    "        input_df\n",
    ") :\n",
    "    # --- 0) Setup ---\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.load(\"email_sp.model\")                 # your trained SentencePiece model\n",
    "    vocab_size = sp.get_piece_size()\n",
    "\n",
    "    # --- Parameters ---\n",
    "    MAX_LEN = 256\n",
    "    pad_id = sp.piece_to_id(\"<pad>\")\n",
    "    if pad_id == -1:   # fallback if no <pad> token defined\n",
    "        pad_id = 0\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def encode_ids(text: str) -> list[int]:\n",
    "        if not isinstance(text, str):\n",
    "            text = \"\" if pd.isna(text) else str(text)\n",
    "        return sp.encode_as_ids(text)\n",
    "\n",
    "    def pad_ids(\n",
    "            ids\n",
    "            , max_len\n",
    "            , pad_id) -> np.ndarray:\n",
    "        \"\"\"Return a NumPy array of fixed length.\"\"\"\n",
    "        if len(ids) >= max_len:\n",
    "            return np.array(ids[:max_len], dtype=np.int32)\n",
    "        return np.array(ids + [pad_id] * (max_len - len(ids)), dtype=np.int32)\n",
    "\n",
    "    # --- Apply to DataFrame ---\n",
    "    df = input_df\n",
    "    df[\"sp_ids\"] = df[\"Body\"].apply(encode_ids)\n",
    "\n",
    "    # overwrite sp_ids_padded with NumPy arrays directly\n",
    "    df[\"sp_ids_padded\"] = df[\"sp_ids\"].apply(lambda ids: pad_ids(ids, MAX_LEN, pad_id))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fe712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Body  Label  \\\n",
      "0  status john im not really sure what happened b...      0   \n",
      "\n",
      "                                              sp_ids  \\\n",
      "0  [7, 9, 10, 33, 25, 9, 7, 38, 20, 19, 11, 13, 3...   \n",
      "\n",
      "                                       sp_ids_padded  \n",
      "0  [7, 9, 10, 33, 25, 9, 7, 38, 20, 19, 11, 13, 3...  \n"
     ]
    }
   ],
   "source": [
    "res = vocab_to_id_mapper(debug_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01519b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_embedder(\n",
    "    input_df\n",
    ") : "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa4213",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
